# Corrective Retrieval-Augmented Generation (C-RAG) ğŸš€

Welcome to **C-RAG**! This project implements a **Corrective Retrieval-Augmented Generation** system to deliver accurate and relevant answers to your questions by combining document retrieval, relevance grading, query transformation, and web search. Built with Python and modern AI tools, itâ€™s designed to be robust and extensible. Letâ€™s dive in! ğŸŒŸ

Read the research paper: arXiv:2401.15884

## ğŸ“– Overview

C-RAG enhances the traditional Retrieval-Augmented Generation (RAG) framework by:
- ğŸ“š **Retrieving** documents from a knowledge base using a Chroma vector store.
- âœ… **Grading** documents for relevance to ensure only the best content is used.
- âœï¸ **Transforming** queries to improve retrieval when needed.
- ğŸŒ **Searching the web** as a fallback for missing information.
- ğŸ’¬ **Generating** precise answers using a language model.

The system is powered by **LangChain**, **Chroma**, **HuggingFace embeddings**, **Grok**, and **Tavily** for web searches, orchestrated via a **StateGraph** workflow. ğŸ›ï¸

## âœ¨ Features

- **Corrective Mechanism**: Filters out irrelevant documents to improve answer quality. ğŸ›¡ï¸
- **Persistent Vector Store**: Saves processed documents for fast reuse. ğŸ’¾
- **Web Search Fallback**: Uses Tavily to fetch real-time web data when needed. ğŸŒ
- **Interactive CLI**: User-friendly interface with `rich` for styled outputs. ğŸ–¥ï¸
- **Modular Workflow**: Extensible graph-based architecture for easy customization. ğŸ§©

## ğŸ› ï¸ Installation

Get started in a few simple steps! ğŸš§

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/ldotmithu/Corrective-Retrieval-Augmented-Generation-C-RAG-.git
   cd Corrective-Retrieval-Augmented-Generation-C-RAG-
   ```

2. **Install Dependencies**:
   Ensure Python 3.8+ is installed, then run:
   ```bash
   pip install langchain langchain-chroma langchain-groq langchain-huggingface langchain-community pydantic rich python-dotenv langgraph
   ```

3. **Set Up Environment Variables**:
   Create a `.env` file in the project root:
   ```plaintext
   GROQ_API_KEY=your_groq_api_key
   TAVILY_API_KEY=your_tavily_api_key
   USER_AGENT=CorrectiveRAG/1.0
   ```
   Get your API keys from [xAI](https://x.ai/api) for Grok and [Tavily](https://tavily.com) for web search.

4. **Run the Application**:
   ```bash
   python main.py
   ```

## ğŸ® Usage

1. Launch the app and see the welcome panel! ğŸ‰
2. Enter your question at the prompt (e.g., `What is an LLM agent?`). â“
3. The system will:
   - Search the knowledge base (Chroma vector store). ğŸ“š
   - Grade documents for relevance. âœ…
   - Rewrite the query or perform a web search if needed. ğŸŒ
   - Generate a clear, concise answer. ğŸ’¬
4. Type `exit`, `quit`, or `q` to stop. ğŸ‘‹

### Example
```plaintext
You: What is an LLM agent?
Agent: An LLM agent is a system that leverages a large language model to perform tasks autonomously by combining reasoning, planning, and interaction with external tools or environments. It typically uses a prompt-driven approach to process inputs, make decisions, and generate responses, often augmented with memory or retrieval mechanisms to access relevant information. For example, an LLM agent might retrieve documents from a knowledge base or perform web searches to answer complex queries, as described in sources like Lilian Wengâ€™s blog on agents. ğŸ§ 
```

## ğŸ“‚ Project Structure

```
Corrective-Retrieval-Augmented-Generation-C-RAG-/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ helper.py          # Utility functions ğŸ› ï¸
â”‚   â”œâ”€â”€ State.py           # AgentState definition ğŸ“‹
â”‚   â”œâ”€â”€ Workflow.py        # Graph workflow setup ğŸ§©
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ Agent_Prompt.py    # Prompts for grading and query rewriting âœï¸
â”œâ”€â”€ main.py                # Main application entry point ğŸš€
â”œâ”€â”€ .env                   # Environment variables ğŸ”
â”œâ”€â”€ README.md              # This file! ğŸ“–
```

## ğŸ”§ How It Works

1. **Initialize Model**: Uses `ChatGroq` (e.g., `qwen/qwen3-32b`) for generation and grading. ğŸ¤–
2. **Build Vector Store**: Loads documents from URLs (e.g., Lilian Wengâ€™s blog posts), splits them into chunks, and stores them in a persistent Chroma vector store. ğŸ“¦
3. **Retrieve Documents**: Fetches relevant documents based on the userâ€™s question. ğŸ”
4. **Grade Documents**: Filters documents using a binary relevance score (`yes`/`no`). âœ…
5. **Transform Query**: Rewrites the question if no relevant documents are found. âœï¸
6. **Web Search**: Falls back to Tavily for external content if needed. ğŸŒ
7. **Generate Answer**: Combines the question and documents to produce a final response. ğŸ’¬

The workflow is managed by a `StateGraph`, ensuring a clear and efficient pipeline. ğŸ›¤ï¸

## ğŸ“š Knowledge Base

The default knowledge base includes:
- [Lilian Wengâ€™s blog on LLM agents](https://lilianweng.github.io/posts/2023-06-23-agent/) ğŸ§ 
- [Lilian Wengâ€™s blog on LLM adversarial attacks](https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/) ğŸ›¡ï¸

You can modify `KNOWLEDGE_BASE_URLS` in the code to add your own sources! ğŸŒŸ

## ğŸ¤ Contributing

We welcome contributions! ğŸ‰ To contribute:
1. Fork the repository. ğŸ´
2. Create a feature branch (`git checkout -b feature/YourFeature`). ğŸŒ¿
3. Commit your changes (`git commit -m "Add YourFeature"`). ğŸ’¾
4. Push to the branch (`git push origin feature/YourFeature`). ğŸš€
5. Open a Pull Request. ğŸ“¬

Please include clear descriptions and test your changes thoroughly. ğŸ§ª

## âš ï¸ Limitations

- **Limited Knowledge Base**: Relies on predefined URLs; expand for broader coverage. ğŸ“š
- **API Dependency**: Requires Grok and Tavily API keys. ğŸ”‘
- **No Graph Visualization**: Workflow graph exists but isnâ€™t displayed by default. ğŸ“Š
- **Prompt Dependency**: Relies on external prompt definitions (`Agent_Prompt.py`). ğŸ“

## ğŸŒŸ Future Improvements

- ğŸ“ Add detailed documentation for prompts and helper functions.
- ğŸŒ Support custom knowledge base URLs or local files.
- ğŸ–¼ï¸ Integrate workflow visualization using Mermaid diagrams.
- ğŸ› ï¸ Enhance error handling for robust API interactions.
- ğŸ¤– Support additional language models or embedding providers.

## ğŸ“œ License

Â© 2025 GitHub, Inc. See the repository for full license details. ğŸ“œ

## ğŸ“¬ Contact

For questions or suggestions, open an issue on the [GitHub repository](https://github.com/ldotmithu/Corrective-Retrieval-Augmented-Generation-C-RAG-) or reach out via GitHub. Letâ€™s make C-RAG even better! ğŸš€

---

Happy querying with C-RAG! ğŸ‰
